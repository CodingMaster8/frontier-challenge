"""Test semantic search with Pinecone + OpenAI"""
import logging
import os
import sys

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from frontier_challenge.tools import SemanticSearchTool

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def main():
    print("=" * 80)
    print("SEMANTIC SEARCH TOOL - PINECONE + OPENAI TEST")
    print("=" * 80)

    # Check environment variables
    if not os.getenv("OPENAI_API_KEY"):
        print("\n‚ùå Error: OPENAI_API_KEY environment variable not set")
        print("Set it with: export OPENAI_API_KEY='sk-proj-...'")
        return False

    if not os.getenv("PINECONE_API_KEY"):
        print("\n‚ùå Error: PINECONE_API_KEY environment variable not set")
        print("Set it with: export PINECONE_API_KEY='pcsk_...'")
        return False

    print("\n‚úÖ API keys found")

    # Initialize tool
    print("\nüì¶ Initializing semantic search tool...")
    tool = SemanticSearchTool()

    # Build or load index
    print("\nüì¶ Building/loading vector index...")
    print("(First time: ~2-3 minutes to generate embeddings)")
    print("(Subsequent: <1 second to load existing index)")

    try:
        build_result = tool.build_index(force_rebuild=False)
        if build_result.success:
            print(f"\n‚úÖ Index ready with {build_result.total_vectors:,} funds")
            print(f"   Rebuild: {build_result.rebuild}")
            print(f"   Time: {build_result.execution_time_ms:.0f}ms")
        else:
            print(f"\n‚ùå Error building index: {build_result.error_message}")
            return False
    except Exception as e:
        print(f"\n‚ùå Error building index: {e}")
        return False

    # Show index stats
    print("\nüìä INDEX STATISTICS")
    print("-" * 80)
    stats = tool.get_index_stats()
    print(f"Index name: {stats.index_name}")
    print(f"Total vectors: {stats.total_vectors:,}")
    print(f"Dimension: {stats.dimension}")
    print(f"Metric: {stats.metric}")
    print(f"Index fullness: {stats.index_fullness:.2%}")

    # Calculate storage usage
    vector_size_kb = (stats.dimension * 4) / 1024  # 4 bytes per float
    total_size_mb = (stats.total_vectors * vector_size_kb) / 1024
    free_tier_gb = 2.0
    usage_pct = (total_size_mb / (free_tier_gb * 1024)) * 100

    print(f"\nüíæ STORAGE ANALYSIS")
    print("-" * 80)
    print(f"Per vector: {vector_size_kb:.2f} KB")
    print(f"Total usage: {total_size_mb:.2f} MB")
    print(f"Free tier: {free_tier_gb} GB")
    print(f"Usage: {usage_pct:.2f}% of free tier")
    print(f"Remaining: {(free_tier_gb * 1024) - total_size_mb:.2f} MB")

    # Test queries
    print("\n" + "=" * 80)
    print("RUNNING TEST QUERIES")
    print("=" * 80)

    test_cases = [
        {
            "query": "Bradesco gold fund",
            "expected": "Should find Bradesco funds related to gold/commodities",
            "top_k": 3
        },
        {
            "query": "fundos de renda fixa conservadores",
            "expected": "Should find conservative fixed income funds",
            "top_k": 3
        },
        {
            "query": "sustainable ESG investing",
            "expected": "Should find ESG/sustainable funds",
            "top_k": 3
        },
        {
            "query": "a√ß√µes de tecnologia",
            "expected": "Should find technology equity funds",
            "top_k": 3
        },
    ]

    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"TEST {i}/{len(test_cases)}")
        print(f"Query: {test['query']}")
        print(f"Expected: {test['expected']}")
        print('-'*80)

        try:
            explanation = tool.search_with_explanation(
                test['query'],
                top_k=test['top_k']
            )
            print(explanation)

            # Also get structured results for validation
            result = tool.search(test['query'], top_k=test['top_k'])

            if not result.success:
                print(f"‚ùå Search failed: {result.error_message}")
            elif not result.matches:
                print("‚ö†Ô∏è  No results found!")
            else:
                print(f"‚úÖ Found {len(result.matches)} results")
                print(f"   Execution time: {result.execution_time_ms:.0f}ms")
                print(f"   Reranked: {result.reranked}")

        except Exception as e:
            print(f"‚ùå Error: {e}")

    # Summary
    print("\n" + "=" * 80)
    print("‚úÖ TESTS COMPLETE")
    print("=" * 80)
    print(f"""
Summary:
- Indexed {build_result.total_vectors:,} Brazilian investment funds
- Using OpenAI {tool.embedding_model} ({tool.dimension}D)
- Stored in Pinecone serverless
- Storage: {total_size_mb:.2f} MB ({usage_pct:.2f}% of free tier)
- Ready for production use!

Next steps:
1. Integrate into agent/CLI
2. Add evaluation metrics
3. Build structured filter tool
4. Build portfolio analysis tool
    """)

    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
